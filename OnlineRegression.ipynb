{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b36ade28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This notebook is to test online linear regression. I want to get it working here\n",
    "# before trying to integrate into the sentiment analysis.\n",
    "\n",
    "import numpy as np\n",
    "import random\n",
    "from sklearn import datasets, linear_model\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from scipy import linalg\n",
    "import sympy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "67320674",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(416.15301008042337,\n",
       " 82.8002593290743,\n",
       " 1010,\n",
       " 0.49901136647134914,\n",
       " 5.025986795844447,\n",
       " 0.506835402394537,\n",
       " 3.046359406572799)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Online linear regression with a single feature is demonstrated here:\n",
    "# https://stackoverflow.com/questions/52070293/efficient-online-linear-regression-algorithm-in-python\n",
    "# Following is a direct lifting of the code in the first answer\n",
    "\n",
    "def lr(x_avg,y_avg,Sxy,Sx,n,new_x,new_y):\n",
    "    \"\"\"\n",
    "    x_avg: average of previous x, if no previous sample, set to 0\n",
    "    y_avg: average of previous y, if no previous sample, set to 0\n",
    "    Sxy: covariance of previous x and y, if no previous sample, set to 0\n",
    "    Sx: variance of previous x, if no previous sample, set to 0\n",
    "    n: number of previous samples\n",
    "    new_x: new incoming 1-D numpy array x\n",
    "    new_y: new incoming 1-D numpy array x\n",
    "    \"\"\"\n",
    "    new_n = n + len(new_x)\n",
    "\n",
    "    new_x_avg = (x_avg*n + np.sum(new_x))/new_n\n",
    "    new_y_avg = (y_avg*n + np.sum(new_y))/new_n\n",
    "\n",
    "    if n > 0:\n",
    "        x_star = (x_avg*np.sqrt(n) + new_x_avg*np.sqrt(new_n))/(np.sqrt(n)+np.sqrt(new_n))\n",
    "        y_star = (y_avg*np.sqrt(n) + new_y_avg*np.sqrt(new_n))/(np.sqrt(n)+np.sqrt(new_n))\n",
    "    elif n == 0:\n",
    "        x_star = new_x_avg\n",
    "        y_star = new_y_avg\n",
    "    else:\n",
    "        raise ValueError\n",
    "\n",
    "    new_Sx = Sx + np.sum((new_x-x_star)**2)\n",
    "    new_Sxy = Sxy + np.sum((new_x-x_star).reshape(-1) * (new_y-y_star).reshape(-1))\n",
    "\n",
    "    beta = new_Sxy/new_Sx\n",
    "    alpha = new_y_avg - beta * new_x_avg\n",
    "    return new_Sxy, new_Sx, new_n, alpha, beta, new_x_avg, new_y_avg\n",
    "\n",
    "# Example of online linear regression applied to 101 batches of random data.\n",
    "x_avg, y_avg, Sxy, Sx, n = 0,0,0,0,0\n",
    "random.seed(1234)\n",
    "X = np.array([random.random() for i in range(10)])\n",
    "y = np.array([random.random() + 5*X[i] for i in range(10)])\n",
    "\n",
    "X_total = X\n",
    "y_total = y\n",
    "\n",
    "Sxy, Sx, n, alpha, beta, x_avg, y_avg = lr(x_avg,y_avg,Sxy,Sx,n, X,y)\n",
    "\n",
    "for i in range(100):\n",
    "    X = np.array([random.random() for i in range(10)])\n",
    "    X_total = np.append(X_total, X)\n",
    "    y = np.array([random.random() + 5*X[i] for i in range(10)])\n",
    "    y_total = np.append(y_total, y)\n",
    "    Sxy, Sx, n, alpha, beta, x_avg, y_avg = lr(x_avg,y_avg,Sxy,Sx,n, X,y)\n",
    "    \n",
    "# Results. alpha and beta are, respectively, the intercept and coefficient of the regression.\n",
    "Sxy, Sx, n, alpha, beta, x_avg, y_avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a195c8fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.4990113664713478, array([5.0259868])]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use scikit learn's linear model to validate the above algorithm\n",
    "# The intercept and coefficient should match the alph and beta values, respectively, found above.\n",
    "regr = linear_model.LinearRegression()\n",
    "regr.fit(X_total.reshape(-1,1), y_total)\n",
    "[regr.intercept_,regr.coef_]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84cb4a83",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8c170182",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we implement multidimensional regression:\n",
    "# The following is based on a formula for regression coefficient, given for example in the following:\n",
    "# https://stattrek.com/multiple-regression/regression-coefficients.aspx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "08929108",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 9.04545455],\n",
       "       [-2.27272727],\n",
       "       [ 1.85227273]])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example for testing\n",
    "y_base = np.array([10,11,12,7,7])\n",
    "X_base = np.array([[1,2],[0,1],[3,5],[2,1],[3,3]])\n",
    "y = y_base.reshape(1,len(y_base)).transpose()\n",
    "X = np.concatenate(([[1]]*len(X_base),X_base), axis=1)\n",
    "XX = np.zeros( ( len(X[0]) , len(X[0]) ) )\n",
    "Xy = np.zeros( ( len(X[0]) , 1 ) )\n",
    "\n",
    "def lr_multi(XX,Xy,X,y, calc_results=False):\n",
    "    XX = np.add(XX, np.matmul(X.transpose(),X))\n",
    "    Xy = np.add(Xy, np.matmul(X.transpose(),y))\n",
    "    if (calc_results):\n",
    "        lin_ind_cols = sympy.Matrix(XX).T.rref()[1]\n",
    "        XX_reduced = [[XX[i][j] for j in range(len(XX[0])) if j in lin_ind_cols] for i in range(len(XX)) if i in lin_ind_cols]\n",
    "        Xy_reduced = [[Xy[i][0]] for i in range(len(XX)) if i in lin_ind_cols]\n",
    "        return XX, Xy, np.matmul( np.linalg.inv(XX_reduced), Xy_reduced )\n",
    "    else:\n",
    "        return XX, Xy, None\n",
    "\n",
    "# Split into 2\n",
    "X1, X2, y1, y2 = X[:3], X[3:], y[:3], y[3:]\n",
    "XX, Xy, _ = lr_multi(XX,Xy,X1,y1)\n",
    "XX, Xy, results = lr_multi(XX,Xy,X2,y2, True)\n",
    "# 'results' is an array. The first element is the intercept, and subsequent elements are\n",
    "# the cofficients of the various features.\n",
    "results"
   ]
  },
  {
   "cell_type": "raw",
   "id": "7634b4f4",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e0050d6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[9.045454545454543, array([-2.27272727,  1.85227273])]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Validate with scikit learn. Should match the intercept and coefficients found above.\n",
    "regr = linear_model.LinearRegression()\n",
    "regr.fit(X_base, y_base)\n",
    "[regr.intercept_, regr.coef_]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "2d22aa78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[11.],\n",
       "       [-1.]])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Another example\n",
    "# Should get a singular matrix X^TX.\n",
    "\n",
    "y_base = np.array([10,11,12,7,7])\n",
    "X_base = np.array([[1,2],[2,4],[1,2],[3,6],[1,2]]) \n",
    "y = y_base.reshape(1,len(y_base)).transpose()\n",
    "X = np.concatenate(([[1]]*len(X_base),X_base), axis=1)\n",
    "XX = np.zeros( ( len(X[0]) , len(X[0]) ) )\n",
    "Xy = np.zeros( ( len(X[0]) , 1 ) )\n",
    "\n",
    "X1,X2,y1,y2 = X[:2],X[2:],y[:2],y[2:]\n",
    "\n",
    "XX, Xy, _ = lr_multi(XX,Xy,X1,y1)\n",
    "XX, Xy, results = lr_multi(XX,Xy,X2,y2,True)\n",
    "# These results are not the same as the results given by scikit-learn's regression.\n",
    "# In the event of the X^TX matrix being singular (linear dependency among features), there is not an umbiguous\n",
    "# regression that minimizes error.\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "07b79fa3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b88a2104",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb567806",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea569ded",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c48f800",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "896a7adf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6a55881",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
